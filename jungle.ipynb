{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "from src.kgrams import *\n",
    "from src.levenshtein import *\n",
    "from sklearn import svm\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(K, Y, folds=5, C_min=-7, C_max=6):\n",
    "    \"\"\"\n",
    "     Grid search on C values, from 10^C_min to 10^C_max, using k-fold cross validation.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for C in 10. ** np.arange(C_min, C_max + 1):\n",
    "        results.append(np.array(evaluate(svm.SVC(kernel='precomputed', C=C), K, Y, folds=folds)))\n",
    "        print('%.0e \\t ' % C,\n",
    "              'Validation %.2f%% +- %.2f\\t Train %.2f%%\\t +- %.2f' %\n",
    "              tuple(100 * results[-1]))\n",
    "    \n",
    "    return 10. ** np.arange(C_min, C_max + 1), results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, train_Xs, train_Ys, test_Xs, Cs, file_name='predictions', **params):\n",
    "    \"\"\"\n",
    "    For each data set, trains the model on the train data, then computes predictions on the test data.\n",
    "    Saves the predictions to the specified file.\n",
    "    \n",
    "    Also evaluates the performance of the specified model using cross-validation on the train data.\n",
    "    \n",
    "    NB: train_Xs and test_Xs can be either precomputed kernel matrices, or simply the train and test features,\n",
    "    depending on the model and parameters.\n",
    "    \"\"\"\n",
    "    # Evaluation using k-fold validation.\n",
    "    print('Evaluation on train data (using cross validation)')\n",
    "    print('Validation %.2f\\%% +- %.2f\\t Train %.2f%%\\t +- %.2f' %\n",
    "          tuple(100 * global_evaluate(model, train_Xs, train_Ys, Cs, **params)))\n",
    "    predictions = []\n",
    "    for k, (X_train, Y_train, X_test, C) in enumerate(zip(train_Xs, train_Ys, test_Xs, Cs)):\n",
    "        model_k = model(C=C, **params)\n",
    "        model_k.fit(X_train, Y_train)\n",
    "        \n",
    "        predictions.append(model_k.predict(X_test))\n",
    "    \n",
    "    predictions = np.concatenate(predictions)\n",
    "    \n",
    "    predictions_dir = 'predictions'\n",
    "    if not os.path.isdir(predictions_dir):\n",
    "        os.mkdir(predictions_dir)\n",
    "    \n",
    "    np.savetxt('%s/%s.csv' % (predictions_dir, file_name),\n",
    "               np.stack((np.arange(len(predictions)),\n",
    "                         predictions), axis=1),\n",
    "               header='Id,Bound', comments='', fmt='%d', delimiter=',')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline using Spectrum kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computations are slowed down over $k=13$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_k = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xs = [load(k=k) for k in range(3)]\n",
    "train_Ys = [load(X=False, k=k) for k in range(3)]\n",
    "test_Xs = [load(k=k, train=False) for k in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tqdm = True\n",
    "\n",
    "train_Ks = [cum_spectrum(train_X, k=spectrum_k, tqdm=tqdm) for train_X in train_Xs]\n",
    "test_Ks  = [cum_spectrum(test_X, train_X, k=spectrum_k, tqdm=tqdm) for (test_X, train_X) in zip(test_Xs, train_Xs)]\n",
    "\n",
    "print(\"Total Duration: %.1f seconds.\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-search to find the best values for parameter C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs0 = grid_search(train_Ks[0], train_Ys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = grid_search(train_Ks[1], train_Ys[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = grid_search(train_Ks[2], train_Ys[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_Cs = [Cs[np.argmax(np.array(scores)[:, 0] - np.array(scores)[:, 1])]\n",
    "             for (Cs, scores) in [gs0, gs1, gs2]]  # Values with best validation score.\n",
    "\n",
    "Cs = (1, 1, 1)               # Values without strong overfitting (i.e. perfect training accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(greedy_Cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating test predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test(svm.SVC,\n",
    "         train_Ks, train_Ys, test_Ks,\n",
    "         Cs=greedy_Cs, kernel='precomputed',\n",
    "         file_name='spectrum_greedy_predictions_%d' % spectrum_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test(svm.SVC,\n",
    "         train_Ks, train_Ys, test_Ks,\n",
    "         Cs=Cs, kernel='precomputed',\n",
    "         file_name='spectrum_soft_predictions_%d' % spectrum_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xs = [load(k=k, numeric=False) for k in range(3)]\n",
    "train_Ys = [load(X=False, k=k) for k in range(3)]\n",
    "test_Xs = [load(k=k, train=False, numeric=False) for k in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tqdm = True\n",
    "\n",
    "train_ds = [levenshtein_distance(train_X, tqdm=tqdm) for train_X in train_Xs]\n",
    "test_ds  = [levenshtein_distance(test_X, train_X, tqdm=tqdm) for (test_X, train_X) in zip(test_Xs, train_Xs)]\n",
    "\n",
    "print(\"Total Duration: %.1f seconds.\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_kernel(d):\n",
    "    return 1 / (1 + d ** .66)\n",
    "#     σ = 10\n",
    "#     return np.exp(-(d / σ)**2)\n",
    "\n",
    "train_Ks = [distance_to_kernel(d) for d in train_ds]\n",
    "test_Ks = [distance_to_kernel(d) for d in test_ds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-search to find the best values for parameter C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs0 = grid_search(train_Ks[0], train_Ys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = grid_search(train_Ks[1], train_Ys[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = grid_search(train_Ks[2], train_Ys[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_Cs = [Cs[np.argmax(np.array(scores)[:, 0] - np.array(scores)[:, 1])]\n",
    "             for (Cs, scores) in [gs0, gs1, gs2]]  # Values with best validation score.\n",
    "\n",
    "Cs = (1, 1, 1)               # Values without strong overfitting (i.e. perfect training accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(greedy_Cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating test predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test(svm.SVC,\n",
    "         train_Ks, train_Ys, test_Ks,\n",
    "         Cs=greedy_Cs, kernel='precomputed',\n",
    "         file_name='spectrum_greedy_predictions_%d' % spectrum_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test(svm.SVC,\n",
    "         train_Ks, train_Ys, test_Ks,\n",
    "         Cs=Cs, kernel='precomputed',\n",
    "         file_name='spectrum_soft_predictions_%d' % spectrum_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
